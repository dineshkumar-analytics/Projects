{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bcd413-e61f-4eac-b0ff-2236b3702422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 20251103 (Men)\n",
      "Fetching 20251104 (Men)\n",
      "Fetching 20251105 (Men)\n",
      "Fetching 20251106 (Men)\n",
      "Fetching 20251107 (Men)\n",
      "Fetching 20251108 (Men)\n",
      "Fetching 20251109 (Men)\n",
      "Fetching 20251110 (Men)\n",
      "Fetching 20251111 (Men)\n",
      "Fetching 20251112 (Men)\n",
      "Fetching 20251113 (Men)\n",
      "Fetching 20251114 (Men)\n",
      "Fetching 20251115 (Men)\n",
      "Fetching 20251116 (Men)\n",
      "Fetching 20251117 (Men)\n",
      "Fetching 20251118 (Men)\n",
      "Fetching 20251119 (Men)\n",
      "Fetching 20251120 (Men)\n",
      "Fetching 20251121 (Men)\n",
      "Fetching 20251122 (Men)\n",
      "Fetching 20251123 (Men)\n",
      "Fetching 20251124 (Men)\n",
      "Fetching 20251125 (Men)\n",
      "Fetching 20251126 (Men)\n",
      "Fetching 20251127 (Men)\n",
      "Fetching 20251128 (Men)\n",
      "Fetching 20251129 (Men)\n",
      "Fetching 20251130 (Men)\n",
      "Fetching 20251201 (Men)\n",
      "Fetching 20251202 (Men)\n",
      "Fetching 20251203 (Men)\n",
      "Fetching 20251204 (Men)\n",
      "Fetching 20251205 (Men)\n",
      "Fetching 20251206 (Men)\n",
      "Fetching 20251207 (Men)\n",
      "Fetching 20251208 (Men)\n",
      "Fetching 20251209 (Men)\n",
      "Fetching 20251210 (Men)\n",
      "Fetching 20251211 (Men)\n",
      "Fetching 20251212 (Men)\n",
      "Fetching 20251213 (Men)\n",
      "Fetching 20251214 (Men)\n",
      "Fetching 20251215 (Men)\n",
      "Fetching 20251216 (Men)\n",
      "Fetching 20251217 (Men)\n",
      "Fetching 20251218 (Men)\n",
      "Fetching 20251219 (Men)\n",
      "Fetching 20251220 (Men)\n",
      "Fetching 20251221 (Men)\n",
      "Fetching 20251222 (Men)\n",
      "Fetching 20251223 (Men)\n",
      "Fetching 20251224 (Men)\n",
      "⚠ No games on 20251224\n",
      "Fetching 20251225 (Men)\n",
      "⚠ No games on 20251225\n",
      "Fetching 20251226 (Men)\n",
      "⚠ No games on 20251226\n",
      "Fetching 20251227 (Men)\n",
      "Fetching 20251228 (Men)\n",
      "Fetching 20251229 (Men)\n",
      "Fetching 20251230 (Men)\n",
      "Fetching 20251231 (Men)\n",
      "Fetching 20260101 (Men)\n",
      "Fetching 20260102 (Men)\n",
      "Fetching 20260103 (Men)\n",
      "Fetching 20260104 (Men)\n",
      "Fetching 20260105 (Men)\n",
      "Fetching 20260106 (Men)\n",
      "Fetching 20260107 (Men)\n",
      "Fetching 20260108 (Men)\n",
      "Fetching 20260109 (Men)\n",
      "Fetching 20260110 (Men)\n",
      "Fetching 20260111 (Men)\n",
      "Fetching 20260112 (Men)\n",
      "Fetching 20260113 (Men)\n",
      "Fetching 20260114 (Men)\n",
      "Fetching 20260115 (Men)\n",
      "Fetching 20260116 (Men)\n",
      "Fetching 20260117 (Men)\n",
      "Fetching 20260118 (Men)\n",
      "Fetching 20260119 (Men)\n",
      "Fetching 20260120 (Men)\n",
      "Fetching 20260121 (Men)\n",
      "Fetching 20260122 (Men)\n",
      "Fetching 20260123 (Men)\n",
      "Fetching 20260124 (Men)\n",
      "Fetching 20260125 (Men)\n",
      "Fetching 20260126 (Men)\n",
      "Fetching 20260127 (Men)\n",
      "Fetching 20260128 (Men)\n",
      "Fetching 20260129 (Men)\n",
      "Fetching 20260130 (Men)\n",
      "Fetching 20260131 (Men)\n",
      "Fetching 20260201 (Men)\n",
      "Fetching 20260202 (Men)\n",
      "Fetching 20260203 (Men)\n",
      "Fetching 20260204 (Men)\n",
      "Fetching 20260205 (Men)\n",
      "Fetching 20260206 (Men)\n",
      "Fetching 20260207 (Men)\n",
      "Fetching 20260208 (Men)\n",
      "Fetching 20260209 (Men)\n",
      "Fetching 20260210 (Men)\n",
      "Fetching 20260211 (Men)\n",
      "Fetching 20260212 (Men)\n",
      "Fetching 20260213 (Men)\n",
      "Fetching 20260214 (Men)\n",
      "Fetching 20260215 (Men)\n",
      "Fetching 20260216 (Men)\n",
      "Fetching 20260217 (Men)\n",
      "Fetching 20260218 (Men)\n",
      "Fetching 20260219 (Men)\n",
      "Fetching 20260220 (Men)\n",
      "Fetching 20260221 (Men)\n",
      "Fetching 20260222 (Men)\n",
      "Fetching 20260223 (Men)\n",
      "Fetching 20260224 (Men)\n",
      "Fetching 20260225 (Men)\n",
      "Fetching 20260226 (Men)\n",
      "Fetching 20260227 (Men)\n",
      "Fetching 20260228 (Men)\n",
      "Fetching 20260301 (Men)\n",
      "Fetching 20260302 (Men)\n",
      "Fetching 20260303 (Men)\n",
      "Fetching 20260304 (Men)\n",
      "Fetching 20260305 (Men)\n",
      "Fetching 20260306 (Men)\n",
      "Fetching 20260307 (Men)\n",
      "Fetching 20260308 (Men)\n",
      "Fetching 20260309 (Men)\n",
      "⚠ No games on 20260309\n",
      "Fetching 20260310 (Men)\n",
      "⚠ No games on 20260310\n",
      "Fetching 20260311 (Men)\n",
      "⚠ No games on 20260311\n",
      "Fetching 20260312 (Men)\n",
      "⚠ No games on 20260312\n",
      "Fetching 20260313 (Men)\n",
      "⚠ No games on 20260313\n",
      "Fetching 20260314 (Men)\n",
      "⚠ No games on 20260314\n",
      "Fetching 20260315 (Men)\n",
      "⚠ No games on 20260315\n",
      "\n",
      "✅ Excel created: ncaa_fixtures_1.xlsx\n",
      "  Date (ET)   Away Team       Home Team Time / Status (ET)     Time (Berlin)  \\\n",
      "0  20251103      Lehigh     @ 2 Houston     HOU 75, LEH 57    HOU 75, LEH 57   \n",
      "1  20251103   3 Florida    v 13 Arizona    ARIZ 93, FLA 87   ARIZ 93, FLA 87   \n",
      "2  20251103   New Haven       @ 4 UConn   CONN 79, NHVN 55  CONN 79, NHVN 55   \n",
      "3  20251103  Quinnipiac  @ 5 St. John's   SJU 108, QUIN 74  SJU 108, QUIN 74   \n",
      "4  20251103     Oakland    @ 7 Michigan   MICH 121, OAK 78  MICH 121, OAK 78   \n",
      "\n",
      "                   Location  \n",
      "0      Emanuel Sharp 24 Pts  \n",
      "1           Koa Peat 30 Pts  \n",
      "2       Alex Karaban 19 Pts  \n",
      "3    Dillon Mitchell 18 Pts  \n",
      "4  Morez Johnson Jr. 24 Pts  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "SPORT_SLUG = {\n",
    "    \"Men\": \"mens-college-basketball\",\n",
    "    \"Women\": \"womens-college-basketball\"\n",
    "}\n",
    "\n",
    "BERLIN_TZ = ZoneInfo(\"Europe/Berlin\")\n",
    "ET_TZ = ZoneInfo(\"America/New_York\")   # ESPN schedules use ET\n",
    "\n",
    "\n",
    "def parse_time_to_berlin(date_str, time_str):\n",
    "    \"\"\"Convert ET game time → Berlin time. If not a time (FINAL, TBD, etc.), return as-is.\"\"\"\n",
    "    try:\n",
    "        dt_et = datetime.strptime(date_str + \" \" + time_str, \"%Y%m%d %I:%M %p\")\n",
    "        dt_et = dt_et.replace(tzinfo=ET_TZ)\n",
    "        dt_berlin = dt_et.astimezone(BERLIN_TZ)\n",
    "        return dt_berlin.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    except:\n",
    "        return time_str\n",
    "\n",
    "\n",
    "def fetch_espn_schedule(date, sport_slug):\n",
    "    url = f\"https://www.espn.com/{sport_slug}/schedule/_/date/{date}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    fixtures = []\n",
    "\n",
    "    tables = soup.select(\"table\")\n",
    "\n",
    "    for table in tables:\n",
    "        rows = table.select(\"tbody tr\")\n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            if len(cols) < 3:\n",
    "                continue\n",
    "\n",
    "            away = cols[0].get_text(\" \", strip=True)\n",
    "            home = cols[1].get_text(\" \", strip=True)\n",
    "            time_status = cols[2].get_text(\" \", strip=True)\n",
    "\n",
    "            location = \"\"\n",
    "            if len(cols) >= 4:\n",
    "                location = cols[3].get_text(\" \", strip=True)\n",
    "\n",
    "            if not away or not home:\n",
    "                continue\n",
    "\n",
    "            fixtures.append({\n",
    "                \"Date (ET)\": date,\n",
    "                \"Away Team\": away,\n",
    "                \"Home Team\": home,\n",
    "                \"Time / Status (ET)\": time_status,\n",
    "                \"Time (Berlin)\": parse_time_to_berlin(date, time_status),\n",
    "                \"Location\": location\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(fixtures)\n",
    "\n",
    "\n",
    "def extract_schedule_to_excel(start_date, end_date, sport, output_file):\n",
    "    sport_slug = SPORT_SLUG[sport]\n",
    "\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    all_data = []\n",
    "    current = start\n",
    "\n",
    "    while current <= end:\n",
    "        date_str = current.strftime(\"%Y%m%d\")\n",
    "        print(f\"Fetching {date_str} ({sport})\")\n",
    "\n",
    "        df = fetch_espn_schedule(date_str, sport_slug)\n",
    "\n",
    "        if not df.empty:\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"⚠ No games on {date_str}\")\n",
    "\n",
    "        time.sleep(1.2)\n",
    "        current += timedelta(days=1)\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        final_df.to_excel(output_file, index=False)\n",
    "        print(f\"\\n✅ Excel created: {output_file}\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"\\n❌ No fixtures found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "final_df = extract_schedule_to_excel(\n",
    "    start_date=\"2025-11-03\",\n",
    "    end_date=\"2026-03-15\",\n",
    "    sport=\"Men\",        # \"Men\" or \"Women\"\n",
    "    output_file=\"ncaa_fixtures_1.xlsx\"\n",
    ")\n",
    "\n",
    "print(final_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
